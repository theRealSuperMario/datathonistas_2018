{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The usual imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import glob2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import preprocessing\n",
    "import progressbar\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ../data\n"
     ]
    }
   ],
   "source": [
    "# Here you can use a user defined path.\n",
    "if os.path.exists(\"datasetpath.txt\"):\n",
    "    dataset_path = open(\"datasetpath.txt\", \"r\").read().replace(\"\\n\", \"\")\n",
    "else:\n",
    "    dataset_path = \"../data\"\n",
    "\n",
    "print(\"Dataset path:\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a grip on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg_paths 4511\n",
      "pcd_paths 4511\n",
      "json_paths 4511\n",
      "json_paths_personal 4511\n",
      "json_paths_measures 4511\n"
     ]
    }
   ],
   "source": [
    "# Getting the paths for images.\n",
    "glob_search_path = os.path.join(dataset_path, \"**/*.jpg\")\n",
    "jpg_paths = glob2.glob(glob_search_path)\n",
    "\n",
    "# Getting the paths for point clouds.\n",
    "glob_search_path = os.path.join(dataset_path, \"**/*.pcd\")\n",
    "pcd_paths = glob2.glob(glob_search_path)\n",
    "\n",
    "# Getting the paths for personal and measurement.\n",
    "glob_search_path = os.path.join(dataset_path, \"**/*.json\")\n",
    "json_paths = glob2.glob(glob_search_path)\n",
    "json_paths_personal = [json_path for json_path in json_paths if \"measures\" not in json_path]\n",
    "json_paths_measures = [json_path for json_path in json_paths if \"measures\" in json_path]\n",
    "\n",
    "print(\"jpg_paths\", len(jpg_paths))\n",
    "print(\"pcd_paths\", len(jpg_paths))\n",
    "print(\"json_paths\", len(jpg_paths))\n",
    "print(\"json_paths_personal\", len(jpg_paths))\n",
    "print(\"json_paths_measures\", len(jpg_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training- and validation-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "SAM-GOV-012 [77.1, 8.1]\n",
      "Found 157 JPGs.\n",
      "SAM-GOV-013 [63, 6.1]\n",
      "Found 136 JPGs.\n",
      "SAM-GOV-014 [91.1, 11.1]\n",
      "Found 279 JPGs.\n",
      "SAM-GOV-002 [67.2, 6.2]\n",
      "Found 144 JPGs.\n",
      "SAM-GOV-025 [67, 6.7]\n",
      "Found 160 JPGs.\n",
      "SAM-GOV-004 [76.2, 8.3]\n",
      "Found 235 JPGs.\n",
      "SAM-GOV-026 [80.1, 9.2]\n",
      "Found 145 JPGs.\n",
      "SAM-GOV-033 [68.7, 6.4]\n",
      "Found 192 JPGs.\n",
      "SAM-GOV-042 [96, 12.7]\n",
      "Found 136 JPGs.\n",
      "SAM-GOV-035 [70.1, 7.1]\n",
      "Found 118 JPGs.\n",
      "SAM-GOV-008 [73.7, 7.1]\n",
      "Found 162 JPGs.\n",
      "SAM-GOV-003 [92.7, 9.7]\n",
      "Found 0 JPGs.\n",
      "SAM-GOV-099 [89.3, 10.8]\n",
      "Found 122 JPGs.\n",
      "SAM-GOV-034 [84.8, 11.1]\n",
      "Found 216 JPGs.\n",
      "SAM-GOV-041 [68.2, 7.1]\n",
      "Found 149 JPGs.\n",
      "SAM-GOV-038 [67.2, 7.6]\n",
      "Found 141 JPGs.\n",
      "SAM-GOV-011 [85.5, 10.8]\n",
      "Found 174 JPGs.\n",
      "SAM-GOV-023 [69.5, 6.5]\n",
      "Found 162 JPGs.\n",
      "SAM-GOV-043 [69.3, 7.6]\n",
      "Found 183 JPGs.\n",
      "\n",
      "Validate:\n",
      "SAM-GOV-003 [75.3, 7.1]\n",
      "Found 0 JPGs.\n",
      "SAM-GOV-005 [76.5, 8.4]\n",
      "Found 262 JPGs.\n",
      "SAM-GOV-036 [68.5, 6.3]\n",
      "Found 457 JPGs.\n",
      "SAM-GOV-037 [65.3, 6.1]\n",
      "Found 165 JPGs.\n",
      "SAM-GOV-044 [64.9, 7.9]\n",
      "Found 142 JPGs.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"height\", \"weight\"]\n",
    "def extract_targets(json_data_measure):\n",
    "    targets = []\n",
    "    for target_name in target_names:\n",
    "        value = json_data_measure[target_name][\"value\"]\n",
    "        targets.append(value)\n",
    "    return targets\n",
    "\n",
    "\n",
    "def extract_qrcode(json_data_measure):\n",
    "    person_id = json_data_measure[\"personId\"][\"value\"]\n",
    "    json_path_personal = [json_path for json_path in json_paths_personal if person_id in json_path]\n",
    "    assert len(json_path_personal) == 1\n",
    "    json_path_personal = json_path_personal[0]\n",
    "    json_data_personal = json.load(open(json_path_personal))\n",
    "    #pprint.pprint(json_data_personal)\n",
    "    qrcode = json_data_personal[\"qrcode\"][\"value\"]\n",
    "    return qrcode\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    img = preprocessing.image.load_img(image_path, target_size=(160, 90))\n",
    "    #img = preprocessing.image.load_img(image_path)\n",
    "    img = img.rotate(-90, expand=True)\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "# Get manual measures.\n",
    "qrcodes_targets = []\n",
    "for json_path_measure in json_paths_measures:\n",
    "    json_data_measure = json.load(open(json_path_measure))\n",
    "\n",
    "    # Ensure manual data.\n",
    "    if json_data_measure[\"type\"][\"value\"] == \"manual\":\n",
    "        targets = extract_targets(json_data_measure)\n",
    "        qrcode = extract_qrcode(json_data_measure)\n",
    "        if qrcode.startswith(\"SAM-GOV\"):\n",
    "            qrcodes_targets.append((qrcode, targets))\n",
    "   \n",
    "# Split.\n",
    "random.shuffle(qrcodes_targets)\n",
    "split_index = int(0.8 * len(qrcodes_targets))\n",
    "qrcodes_targets_train = qrcodes_targets[:split_index]\n",
    "qrcodes_targets_validate = qrcodes_targets[split_index:]\n",
    "del qrcodes_targets\n",
    "\n",
    "def process_qrcodes_target(qrcodes_targets):\n",
    "    \n",
    "    x_images = []\n",
    "    y_targets = []\n",
    "    for qrcode, targets in qrcodes_targets:\n",
    "        print(qrcode, targets)\n",
    "        glob_search_path = os.path.join(dataset_path, \"storage/person\", qrcode, \"measurements\", \"**/*.jpg\")\n",
    "        #print(glob_search_path)\n",
    "        #if not os.path.exists(glob_search_path):\n",
    "        #    continue\n",
    "        jpg_paths = glob2.glob(glob_search_path, recursive=True)\n",
    "        print(\"Found\", len(jpg_paths), \"JPGs.\")\n",
    "        for jpg_path in jpg_paths:\n",
    "            image = load_image(jpg_path)\n",
    "            x_images.append(image)\n",
    "            y_targets.append(targets)\n",
    "        \n",
    "    x_images = np.array(x_images)\n",
    "    y_targets = np.array(y_targets)\n",
    "    assert len(x_images) == len(y_targets)\n",
    "    return x_images, y_targets\n",
    "    \n",
    "        \n",
    "print(\"Train:\")\n",
    "x_train, y_train = process_qrcodes_target(qrcodes_targets_train)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Validate:\")\n",
    "x_validate, y_validate = process_qrcodes_target(qrcodes_targets_validate)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Flatten(input_shape=(90, 160, 3)))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(2))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_validate, y_validate)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history[\"mean_absolute_error\"])\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
