{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristanbehrens/Development/python-venvs/venv-3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from datagenerator import DataGenerator\n",
    "import datetime\n",
    "import pickle\n",
    "from pyntcloud import PyntCloud\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import modelutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hook to the proper dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"datasetpath.txt\"):\n",
    "    dataset_path = open(\"datasetpath.txt\", \"r\").read().replace(\"\\n\", \"\")\n",
    "else:\n",
    "    dataset_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a data-generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Multiple manual measurements for QR-code: SAM-GOV-049 ../data/db/persons/c79b708e301d9c71_shaikh_1531300004131_40Aq4RZQ3gUZts74/measures/c79b708e301d9c71_measure_1531300841811_Lhp0PzvwnmlyRspG/c79b708e301d9c71_measure_1531300841811_Lhp0PzvwnmlyRspG.json\n",
      "WARNING! Multiple manual measurements for QR-code: SAM-SNG-014 ../data/db/persons/f2467a1fb0c542b9_kamble_1530687006027_AVA2AqQDcVsHYrrK/measures/f2467a1fb0c542b9_measure_1531291525951_BhMYXh4Zeu9Jk7Zr/f2467a1fb0c542b9_measure_1531291525951_BhMYXh4Zeu9Jk7Zr.json\n",
      "WARNING! Multiple manual measurements for QR-code: SAM-SNG-096 ../data/db/persons/f2467a1fb0c542b9_kamble_1530687464869_e6puVVsetdSpP7sH/measures/f2467a1fb0c542b9_measure_1531291761123_0ZS7kMnJLy70pe4I/f2467a1fb0c542b9_measure_1531291761123_0ZS7kMnJLy70pe4I.json\n",
      "jpg_paths 7076\n",
      "pcd_paths 2129\n",
      "json_paths_personal 62\n",
      "json_paths_measures 110\n",
      "QR-Codes:\n",
      "SAM-GOV-001\n",
      "SAM-GOV-002\n",
      "SAM-GOV-004\n",
      "SAM-GOV-005\n",
      "SAM-GOV-008\n",
      "SAM-GOV-011\n",
      "SAM-GOV-012\n",
      "SAM-GOV-013\n",
      "SAM-GOV-014\n",
      "SAM-GOV-023\n",
      "SAM-GOV-025\n",
      "SAM-GOV-026\n",
      "SAM-GOV-033\n",
      "SAM-GOV-034\n",
      "SAM-GOV-035\n",
      "SAM-GOV-036\n",
      "SAM-GOV-037\n",
      "SAM-GOV-038\n",
      "SAM-GOV-041\n",
      "SAM-GOV-042\n",
      "SAM-GOV-043\n",
      "SAM-GOV-044\n",
      "SAM-GOV-045\n",
      "SAM-GOV-046\n",
      "SAM-GOV-049\n",
      "SAM-GOV-050\n",
      "SAM-GOV-052\n",
      "SAM-GOV-054\n",
      "SAM-GOV-087\n",
      "SAM-GOV-099\n",
      "SAM-SNG-011\n",
      "SAM-SNG-012\n",
      "SAM-SNG-013\n",
      "SAM-SNG-014\n",
      "SAM-SNG-015\n",
      "SAM-SNG-016\n",
      "SAM-SNG-021\n",
      "SAM-SNG-036\n",
      "SAM-SNG-066\n",
      "SAM-SNG-067\n",
      "SAM-SNG-070\n",
      "SAM-SNG-072\n",
      "SAM-SNG-073\n",
      "SAM-SNG-075\n",
      "SAM-SNG-083\n",
      "SAM-SNG-084\n",
      "SAM-SNG-085\n",
      "SAM-SNG-087\n",
      "SAM-SNG-088\n",
      "SAM-SNG-091\n",
      "SAM-SNG-096\n",
      "SAM-SNG-097\n",
      "SAM-SNG-098\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_generator = DataGenerator(dataset_path=dataset_path, input_type=\"voxelgrid\", output_targets=[\"height\", \"weight\"])\n",
    "\n",
    "print(\"jpg_paths\", len(data_generator.jpg_paths))\n",
    "print(\"pcd_paths\", len(data_generator.pcd_paths))\n",
    "print(\"json_paths_personal\", len(data_generator.json_paths_personal))\n",
    "print(\"json_paths_measures\", len(data_generator.json_paths_measures))\n",
    "print(\"QR-Codes:\\n\" + \"\\n\".join(data_generator.qrcodes))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the train-validate-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR-Codes train:\n",
      "SAM-GOV-023 SAM-GOV-041 SAM-GOV-033 SAM-GOV-037 SAM-GOV-012 SAM-GOV-099 SAM-GOV-001 SAM-GOV-035 SAM-GOV-002 SAM-GOV-038 SAM-GOV-008 SAM-GOV-025 SAM-GOV-034 SAM-GOV-036 SAM-GOV-004 SAM-GOV-014 SAM-GOV-043 SAM-GOV-011 SAM-GOV-042\n",
      "\n",
      "QR-Codes validate:\n",
      "SAM-GOV-013 SAM-GOV-026 SAM-GOV-003 SAM-GOV-044 SAM-GOV-005\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the split is always the same.\n",
    "random.seed(108)\n",
    "\n",
    "# Filter and shuffle the QR-Codes.\n",
    "qrcodes_shuffle = list(data_generator.qrcodes)\n",
    "qrcodes_shuffle = [qrcode for qrcode in qrcodes_shuffle if qrcode.startswith(\"SAM-GOV\")]\n",
    "random.shuffle(qrcodes_shuffle)\n",
    "\n",
    "# Do the split.\n",
    "split_index = int(0.8 * len(qrcodes_shuffle))\n",
    "qrcodes_train = qrcodes_shuffle[:split_index]\n",
    "qrcodes_validate = qrcodes_shuffle[split_index:]\n",
    "del qrcodes_shuffle\n",
    "\n",
    "# Print statistics.\n",
    "print(\"QR-Codes train:\")\n",
    "print(\" \".join(qrcodes_train))\n",
    "print(\"\")\n",
    "print(\"QR-Codes validate:\")\n",
    "print(\" \".join(qrcodes_validate))\n",
    "print(\"\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train several nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: baseline-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 4,202,818\n",
      "Trainable params: 4,202,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qrcodes_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-717d04896bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     history = model.fit_generator(\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrcodes_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqrcodes_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qrcodes_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters.\n",
    "batch_size = 32\n",
    "step_per_epoch = 32\n",
    "epochs = 10\n",
    "validation_steps = 8\n",
    "\n",
    "\n",
    "# Create the models.\n",
    "models_to_train = []\n",
    "models_to_train.append(modelutils.create_dense_model(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(modelutils.create_voxnet_model_small(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(modelutils.create_voxnet_model_big(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(modelutils.create_voxnet_model_homepage(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "\n",
    "# Train the models.\n",
    "histories = []\n",
    "for model in models_to_train:\n",
    "\n",
    "    # Some output.\n",
    "    print(\"Training:\", model.name)\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "            optimizer=\"rmsprop\",\n",
    "            loss=\"mse\",\n",
    "            metrics=[\"mae\"]\n",
    "        )\n",
    "    \n",
    "    # Train the model.\n",
    "    history = model.fit_generator(\n",
    "        data_generator.generate(size=batch_size, qrcodes_to_use=qrcodes_train),\n",
    "        steps_per_epoch=step_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=data_generator.generate(size=batch_size, qrcodes_to_use=qrcodes_validate),\n",
    "        validation_steps=validation_steps)\n",
    "    \n",
    "    histories.append(history)\n",
    "    print(\"Done.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_string = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# Save the models and histories.    \n",
    "for model in models_to_train:\n",
    "    model_name = datetime_string + \"-\" + model.name\n",
    "    model_path = os.path.join(model_name)\n",
    "    #model.save(model_path + \".h5\")\n",
    "    #pickle.dump(history, open(model_path + \".p\", \"wb\"))\n",
    "    print(\"Model saved to:\", model_path)\n",
    "    \n",
    "print(\"All saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, history in histories:\n",
    "    model = models_to_train[i]\n",
    "    for key, data in history.history.items():\n",
    "        plt.plot(data, label=model.name + \"-\" + key)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
